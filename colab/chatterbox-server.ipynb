{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatterbox TTS Server — UdemyCrores Voice Clone\n",
    "\n",
    "**Setup:**\n",
    "1. Make sure GPU runtime is enabled: Runtime → Change runtime type → T4 GPU\n",
    "2. Run all cells in order\n",
    "3. Copy the ngrok URL printed at the end\n",
    "4. Paste it in your `.env` file as `CHATTERBOX_API_URL=<url>`\n",
    "\n",
    "Voice reference is automatically downloaded from the GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Install Chatterbox TTS + dependencies\nimport sys, os\n\n# Use Colab's pre-installed torch 2.9.0, torchaudio, torchvision, numpy\n# Install only chatterbox's other dependencies (compatible versions)\n!pip install -q librosa==0.11.0 s3tokenizer transformers diffusers\n!pip install -q resemble-perth conformer safetensors\n!pip install -q spacy-pkuseg pykakasi==2.3.0 pyloudnorm omegaconf\n!pip install -q pyngrok flask soundfile\n\n# Clone chatterbox source\n!rm -rf /content/chatterbox\n!git clone -q https://github.com/resemble-ai/chatterbox.git /content/chatterbox\n\n# Patch __init__ to skip version lookup\nwith open('/content/chatterbox/src/chatterbox/__init__.py', 'w') as f:\n  f.write('__version__ = \"0.1.6\"\\n')\n\n# Add to path\nsys.path.insert(0, '/content/chatterbox/src')\n\n# Verify import\nfrom chatterbox.tts import ChatterboxTTS\nprint(\"✅ chatterbox.tts imported successfully!\")\nprint(\"✅ Installation complete!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Download voice reference from GitHub repo\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "VOICE_URL = 'https://github.com/JineeshTS/UdemyTrainings/raw/main/data/voice-reference.wav'\n",
    "VOICE_FILE = '/content/voice-reference.wav'\n",
    "\n",
    "if not os.path.exists(VOICE_FILE):\n",
    "    print('Downloading voice reference from GitHub...')\n",
    "    urllib.request.urlretrieve(VOICE_URL, VOICE_FILE)\n",
    "    print(f'Downloaded: {VOICE_FILE} ({os.path.getsize(VOICE_FILE)} bytes)')\n",
    "else:\n",
    "    print(f'Voice reference already exists: {VOICE_FILE}')\n",
    "\n",
    "# Or upload your own:\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# VOICE_FILE = list(uploaded.keys())[0]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 3: Load Chatterbox model\nimport sys\nsys.path.insert(0, '/content/chatterbox/src')\n\nimport torch\nimport soundfile as sf\nfrom chatterbox.tts import ChatterboxTTS\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Device: {device}')\n\nmodel = ChatterboxTTS.from_pretrained(device=device)\nprint('Chatterbox model loaded!')\n\n# Test with voice reference\ntest_wav = model.generate(\"Hello, welcome to the course.\", audio_prompt_path=VOICE_FILE)\nwav_np = test_wav.squeeze().cpu().numpy()\nsf.write('/content/test-output.wav', wav_np, model.sr)\nprint('Test generation successful!')\n\nfrom IPython.display import Audio\nAudio('/content/test-output.wav')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 4: Start OpenAI-compatible TTS API server with ngrok\nfrom pyngrok import ngrok\nfrom flask import Flask, request, send_file, jsonify\nimport io\nimport soundfile as sf\nimport numpy as np\nimport threading\n\n# ============================================\n# SET YOUR NGROK AUTH TOKEN HERE\n# Get free token from: https://dashboard.ngrok.com/get-started/your-authtoken\nNGROK_AUTH_TOKEN = 'YOUR_NGROK_TOKEN_HERE'  # <-- REPLACE THIS\n# ============================================\n\nngrok.set_auth_token(NGROK_AUTH_TOKEN)\n\napp = Flask(__name__)\n\n@app.route('/health', methods=['GET'])\ndef health():\n    return jsonify({'status': 'ok', 'model': 'chatterbox', 'device': device})\n\n@app.route('/v1/audio/speech', methods=['POST'])\ndef tts():\n    data = request.json\n    text = data.get('input', '')\n    if not text:\n        return jsonify({'error': 'No input text'}), 400\n\n    # Voice cloning tuning parameters (from client or defaults)\n    # exaggeration: 0.0 = closest to reference voice, 1.0 = most expressive\n    # cfg: higher = more faithful to reference (3-7 range)\n    exaggeration = data.get('exaggeration', 0.3)\n    cfg = data.get('cfg', 5.0)\n\n    print(f'Generating (exag={exaggeration}, cfg={cfg}): {text[:80]}...')\n    wav = model.generate(\n        text,\n        audio_prompt_path=VOICE_FILE,\n        exaggeration=exaggeration,\n        cfg_weight=cfg\n    )\n\n    wav_np = wav.squeeze().cpu().numpy()\n    buf = io.BytesIO()\n    sf.write(buf, wav_np, model.sr, format='WAV')\n    buf.seek(0)\n\n    return send_file(buf, mimetype='audio/wav', as_attachment=True, download_name='speech.wav')\n\n# Start ngrok tunnel\ntunnel = ngrok.connect(8000)\nprint(f'''\n╔══════════════════════════════════════════════════════════╗\n║  CHATTERBOX TTS SERVER RUNNING                         ║\n║                                                        ║\n║  API URL: {str(tunnel.public_url):45s}║\n║                                                        ║\n║  Voice cloning params (sent from client):              ║\n║    exaggeration: 0.3 (low = closer to your voice)      ║\n║    cfg: 5.0 (high = more faithful clone)               ║\n║                                                        ║\n║  Add to .env:                                          ║\n║  CHATTERBOX_API_URL={str(tunnel.public_url):37s}║\n╚══════════════════════════════════════════════════════════╝\n''')\n\n# Run Flask in thread so Colab stays responsive\nthreading.Thread(target=lambda: app.run(host='0.0.0.0', port=8000), daemon=True).start()\n\n# Keep alive\nimport time\nwhile True:\n    time.sleep(60)\n    print(f'Server running... {tunnel.public_url}')",
   "execution_count": null,
   "outputs": []
  }
 ]
}